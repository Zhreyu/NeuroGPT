{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T16:27:20.919988Z",
     "start_time": "2024-03-17T16:27:20.908332Z"
    }
   },
   "source": [
    "# BCIC data analysis\n",
    "\n",
    "<p>\n",
    "This notebook contains code for preparing the BCIC data for fine-tuning step.\n",
    "</p>\n",
    "\n",
    "---\n",
    "> Author:    Mahmoud Zeydabadinezhad    \n",
    "> Contact:   zeydabadi@gmail.com   \n",
    "> Version:   10/25/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sBa_NPQKo5rg"
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import copy\n",
    "import os\n",
    "import shutil\n",
    "from math import ceil\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\shreyas\\\\Documents\\\\GitHub\\\\NeuroGPT\\\\src')\n",
    "# Third-party library imports\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from rich import print\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.model import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_map = {\n",
    "    \"EEG-Fz\": \"FZ\",\n",
    "    \"EEG-0\": \"FC3\",\n",
    "    \"EEG-1\": \"FC1\",\n",
    "    \"EEG-2\": \"FCZ\",\n",
    "    \"EEG-3\": \"FC2\",\n",
    "    \"EEG-4\": \"FC4\",\n",
    "    \"EEG-5\": \"C5\",\n",
    "    \"EEG-C3\": \"C3\",\n",
    "    \"EEG-6\": \"C1\",\n",
    "    \"EEG-Cz\": \"CZ\",\n",
    "    \"EEG-7\": \"C2\",\n",
    "    \"EEG-C4\": \"C4\",\n",
    "    \"EEG-8\": \"C6\",\n",
    "    \"EEG-9\": \"CP3\",\n",
    "    \"EEG-10\": \"CP1\",\n",
    "    \"EEG-11\": \"CPZ\",\n",
    "    \"EEG-12\": \"CP2\",\n",
    "    \"EEG-13\": \"CP4\",\n",
    "    \"EEG-14\": \"P1\",\n",
    "    \"EEG-Pz\": \"PZ\",\n",
    "    \"EEG-15\": \"P2\",\n",
    "    \"EEG-16\": \"POZ\",\n",
    "}\n",
    "ch_list = [\n",
    "    \"FP1\",\n",
    "    \"FP2\",\n",
    "    \"F7\",\n",
    "    \"F3\",\n",
    "    \"FZ\",\n",
    "    \"F4\",\n",
    "    \"F8\",\n",
    "    \"T3\",\n",
    "    \"C3\",\n",
    "    \"CZ\",\n",
    "    \"C4\",\n",
    "    \"T4\",\n",
    "    \"T5\",\n",
    "    \"P3\",\n",
    "    \"PZ\",\n",
    "    \"P4\",\n",
    "    \"T6\",\n",
    "    \"O1\",\n",
    "    \"O2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_with_values_in_list = [key for key, value in ch_map.items() if value in ch_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">EEG-Fz\n",
       "</pre>\n"
      ],
      "text/plain": [
       "EEG-Fz\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(keys_with_values_in_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_eeg_data(folder_path, ch_map):\n",
    "    files_for_investigation = []\n",
    "    sex_list = []\n",
    "    age_list = []\n",
    "    min_values = []\n",
    "    max_values = []\n",
    "\n",
    "    # Task 2: List all files with '-PSG.edf' in their names\n",
    "    files = [\n",
    "        f for f in os.listdir(folder_path) if \".gdf\" in f\n",
    "    ]  # T for Train, E for Evaluation\n",
    "    print(files)\n",
    "    print(f\"Number of files: {len(files)}\")\n",
    "\n",
    "    # Task 3: Read each file and verify certain properties\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        try:\n",
    "            tmp = mne.io.read_raw_gdf(\n",
    "                os.path.join(folder_path, file),\n",
    "                exclude=[\"EOG-left\", \"EOG-central\", \"EOG-right\"],\n",
    "                preload=True,\n",
    "            )\n",
    "            # Task 4: Get min and max values\n",
    "            data = tmp.get_data()\n",
    "            print(data.shape)\n",
    "            min_values.append(np.min(data))\n",
    "            max_values.append(np.max(data))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "            files_for_investigation.append(file)\n",
    "\n",
    "    return files_for_investigation, min_values, max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A01E.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A01T.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A02E.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A02T.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A03E.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A03T.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A04E.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A04T.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A05E.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A05T.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A06E.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A06T.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A07E.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A07T.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A08E.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A08T.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A09E.gdf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'A09T.gdf'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'A01E.gdf'\u001b[0m,\n",
       "    \u001b[32m'A01T.gdf'\u001b[0m,\n",
       "    \u001b[32m'A02E.gdf'\u001b[0m,\n",
       "    \u001b[32m'A02T.gdf'\u001b[0m,\n",
       "    \u001b[32m'A03E.gdf'\u001b[0m,\n",
       "    \u001b[32m'A03T.gdf'\u001b[0m,\n",
       "    \u001b[32m'A04E.gdf'\u001b[0m,\n",
       "    \u001b[32m'A04T.gdf'\u001b[0m,\n",
       "    \u001b[32m'A05E.gdf'\u001b[0m,\n",
       "    \u001b[32m'A05T.gdf'\u001b[0m,\n",
       "    \u001b[32m'A06E.gdf'\u001b[0m,\n",
       "    \u001b[32m'A06T.gdf'\u001b[0m,\n",
       "    \u001b[32m'A07E.gdf'\u001b[0m,\n",
       "    \u001b[32m'A07T.gdf'\u001b[0m,\n",
       "    \u001b[32m'A08E.gdf'\u001b[0m,\n",
       "    \u001b[32m'A08T.gdf'\u001b[0m,\n",
       "    \u001b[32m'A09E.gdf'\u001b[0m,\n",
       "    \u001b[32m'A09T.gdf'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Number of files: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Number of files: \u001b[1;36m18\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A01E.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A01E.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A01E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686999  =      0.000 ...  2747.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">687000</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m687000\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A01T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A01T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">672528</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m672528\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A02E.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A02E.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A02E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 662665  =      0.000 ...  2650.660 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">662666</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m662666\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A02T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A02T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 677168  =      0.000 ...  2708.672 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">677169</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m677169\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A03E.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A03E.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A03E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 648774  =      0.000 ...  2595.096 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">648775</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m648775\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A03T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A03T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660529  =      0.000 ...  2642.116 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">660530</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m660530\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A04E.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A04E.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A04E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660046  =      0.000 ...  2640.184 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">660047</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m660047\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A04T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A04T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A04T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 600914  =      0.000 ...  2403.656 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600915</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m600915\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A05E.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A05E.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A05E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 679862  =      0.000 ...  2719.448 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">679863</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m679863\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A05T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A05T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A05T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686119  =      0.000 ...  2744.476 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">686120</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m686120\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A06E.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A06E.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A06E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 666372  =      0.000 ...  2665.488 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">666373</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m666373\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A06T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A06T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A06T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 678979  =      0.000 ...  2715.916 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678980</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m678980\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A07E.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A07E.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A07E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673134  =      0.000 ...  2692.536 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">673135</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m673135\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A07T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A07T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 681070  =      0.000 ...  2724.280 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">681071</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m681071\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A08E.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A08E.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A08E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 687791  =      0.000 ...  2751.164 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">687792</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m687792\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A08T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A08T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A08T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675269  =      0.000 ...  2701.076 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">675270</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m675270\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A09E.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A09E.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A09E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675097  =      0.000 ...  2700.388 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">675098</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m675098\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">A09T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "A09T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\BCICIV_2a_gdf\\A09T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673327  =      0.000 ...  2693.308 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">673328</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m, \u001b[1;36m673328\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_dir = \"src/BCICIV_2a_gdf\"\n",
    "files_for_investigation, min_values, max_values = analyze_eeg_data(source_dir, ch_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "iYXwAQXVOa12"
   },
   "outputs": [],
   "source": [
    "ds_max, ds_min = 100, -100\n",
    "\n",
    "def scaler(x):\n",
    "    \"\"\"\n",
    "    Scales the input array x to the range [-1, 1].\n",
    "\n",
    "    Parameters:\n",
    "    - x (numpy.ndarray): The input array to be scaled.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The scaled array.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If the input is not a numpy array.\n",
    "    - ValueError: If the input array is empty.\n",
    "    - ZeroDivisionError: If the max and min values of the array are the same.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if input is a numpy array\n",
    "    if not isinstance(x, np.ndarray):\n",
    "        raise ValueError(\"Input must be a numpy array.\")\n",
    "\n",
    "    # Check if the array is empty\n",
    "    if x.size == 0:\n",
    "        raise ValueError(\"Input array must not be empty.\")\n",
    "\n",
    "    # Calculate min and max\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "\n",
    "    # Check for division by zero\n",
    "    if x_max == x_min:\n",
    "        x_scaled = x / x_max if x_max != 0 else np.zeros_like(x)\n",
    "        return x_scaled\n",
    "\n",
    "    # Perform scaling\n",
    "    x_std = (x - x_min) / (x_max - x_min)\n",
    "    x_scaled = (x_std * 2) - 1\n",
    "\n",
    "    return x_scaled\n",
    "\n",
    "\n",
    "def process_file(raw, ch_map, ch_list, ds_max, ds_min):\n",
    "    # selects 19 standard channels and adds a 20th\n",
    "    raw = raw.copy()\n",
    "    try:\n",
    "        raw = raw.pick(ch_list)\n",
    "    except ValueError as v:\n",
    "        pl = v.args[0].split(\"[\")[1].split(\"]\")[0].split(\",\")\n",
    "        pl = [p.strip(\" ' \") for p in pl]\n",
    "        new_pick = list(set(ch_list) - set(pl))\n",
    "        raw = raw.pick(new_pick)\n",
    "\n",
    "    if len(raw.ch_names) != len(ch_list):\n",
    "        missing_channels = [ch for ch in ch_list if ch not in raw.ch_names]\n",
    "\n",
    "        new_channel_data = np.vstack(\n",
    "            [np.full((1, raw.n_times), 0)] * len(missing_channels)\n",
    "        )\n",
    "        new_channel_info = mne.create_info(\n",
    "            ch_names=missing_channels,\n",
    "            sfreq=raw.info[\"sfreq\"],\n",
    "            ch_types=[\"eeg\"] * len(missing_channels),\n",
    "        )\n",
    "        new_channel_raw = mne.io.RawArray(\n",
    "            data=new_channel_data, info=new_channel_info, first_samp=raw.first_samp\n",
    "        )\n",
    "        raw.load_data().add_channels([new_channel_raw], force_update_info=True)\n",
    "\n",
    "    try:\n",
    "        # raw = raw.rename_channels(ch_map)\n",
    "        raw = raw.reorder_channels(ch_list)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in renaming or reordering channels: {e}\")\n",
    "        return None\n",
    "\n",
    "    # scale\n",
    "    trial_min = np.min(raw.get_data())\n",
    "    trial_max = np.max(raw.get_data())\n",
    "    raw = raw.load_data().apply_function(scaler, channel_wise=False)\n",
    "\n",
    "    # add compensation channel\n",
    "    compensation = (trial_max - trial_min) / (ds_max - ds_min)\n",
    "    comp_ch_data = np.full((1, raw.n_times), compensation)\n",
    "    comp_ch_info = mne.create_info(\n",
    "        ch_names=[\"compensation\"], sfreq=raw.info[\"sfreq\"], ch_types=\"misc\"\n",
    "    )\n",
    "    comp_ch_raw = mne.io.RawArray(\n",
    "        data=comp_ch_data, info=comp_ch_info, first_samp=raw.first_samp\n",
    "    )\n",
    "    raw.add_channels([comp_ch_raw], force_update_info=True)\n",
    "    \n",
    "    return raw\n",
    "\n",
    "\n",
    "def process_gdf_file(gdf_file):\n",
    "    print(\"the file to be processed is: \", gdf_file)\n",
    "    try:\n",
    "        f = mne.io.read_raw_gdf(\n",
    "            gdf_file, eog=[\"EOG-left\", \"EOG-central\", \"EOG-right\"], preload=True\n",
    "        )\n",
    "        f.drop_channels([\"EOG-left\", \"EOG-central\", \"EOG-right\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading EDF file {gdf_file}: {e}\")\n",
    "        return\n",
    "\n",
    "    assert \"lowpass\" in f.info, \"lowpass information is not available in f.info\"\n",
    "    assert f.info[\"lowpass\"] > 0, \"lowpass frequency should be greater than 0\"\n",
    "    assert f.info[\"sfreq\"] > 0, \"Sampling frequency should be greater than 0\"\n",
    "\n",
    "    if f.info[\"bads\"]:\n",
    "        print(f\"Warning: The following channels are marked as bad: {f.info['bads']}\")\n",
    "        print(gdf_file)\n",
    "        # input(\"Press Enter to continue or Ctrl+C to abort.\")\n",
    "\n",
    "    if 256 >= 2 * f.info.get(\"lowpass\", 0):\n",
    "        try:\n",
    "            f = f.resample(sfreq=256)\n",
    "            f = f.rename_channels(ch_map)\n",
    "            f = process_file(\n",
    "                f,\n",
    "                ch_map=ch_map,\n",
    "                ch_list=ch_list,\n",
    "                ds_max=ds_max,\n",
    "                ds_min=ds_min,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"An error occurred while processing the file {gdf_file}: {e} or while resampling\"\n",
    "            )\n",
    "            # continue\n",
    "\n",
    "        event_id = {\"769\": 0, \"770\": 1, \"771\": 2, \"772\": 3}\n",
    "        events = mne.events_from_annotations(f, event_id=event_id)\n",
    "        epochs = mne.Epochs(\n",
    "            f, events[0], [0, 1, 2, 3], tmin=-2, tmax=4, on_missing=\"warn\"\n",
    "        )\n",
    "        # print(\"here\", np.max(f.get_data()), np.min(f.get_data()))\n",
    "        df = epochs.to_data_frame(scalings=dict(eeg=1, mag=1, grad=1))\n",
    "        # print(\"df\", df.iloc[:, 3:].values.max(), df.iloc[:, 3:].values.min())\n",
    "        df[\"person\"] = f.info[\"subject_info\"][\"his_id\"]\n",
    "        indices = [(f.info[\"subject_info\"][\"his_id\"], ep) for ep in df.epoch.unique()]\n",
    "\n",
    "        return df, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Msuh1ndMmW5Z"
   },
   "outputs": [],
   "source": [
    "mne.set_log_level(\"WARNING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "j98QqxkCv5ZU"
   },
   "outputs": [],
   "source": [
    "class EEGDatasetCls(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, idxs):\n",
    "        self.df = df.sort_index()\n",
    "        self.idxs = idxs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.df.loc[self.idxs[idx]].iloc[:, 1:]\n",
    "        label = self.df.loc[self.idxs[idx]].iloc[:, 0].unique().astype(int)\n",
    "\n",
    "        return torch.Tensor(data.values.T), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "SgM53q04uDsO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully copied src/BCICIV_2a_gdf\\A01T.gdf to train\\A01T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Successfully copied src/BCICIV_2a_gdf\\A01T.gdf to train\\A01T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully copied src/BCICIV_2a_gdf\\A02T.gdf to train\\A02T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Successfully copied src/BCICIV_2a_gdf\\A02T.gdf to train\\A02T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully copied src/BCICIV_2a_gdf\\A03T.gdf to train\\A03T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Successfully copied src/BCICIV_2a_gdf\\A03T.gdf to train\\A03T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully copied src/BCICIV_2a_gdf\\A04T.gdf to train\\A04T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Successfully copied src/BCICIV_2a_gdf\\A04T.gdf to train\\A04T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully copied src/BCICIV_2a_gdf\\A05T.gdf to train\\A05T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Successfully copied src/BCICIV_2a_gdf\\A05T.gdf to train\\A05T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully copied src/BCICIV_2a_gdf\\A06T.gdf to train\\A06T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Successfully copied src/BCICIV_2a_gdf\\A06T.gdf to train\\A06T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully copied src/BCICIV_2a_gdf\\A07T.gdf to train\\A07T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Successfully copied src/BCICIV_2a_gdf\\A07T.gdf to train\\A07T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully copied src/BCICIV_2a_gdf\\A08T.gdf to train\\A08T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Successfully copied src/BCICIV_2a_gdf\\A08T.gdf to train\\A08T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully copied src/BCICIV_2a_gdf\\A09T.gdf to train\\A09T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Successfully copied src/BCICIV_2a_gdf\\A09T.gdf to train\\A09T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the source and destination directories\n",
    "\n",
    "dest_dir = \"train\"\n",
    "\n",
    "# Ensure the destination directory exists, if not create it\n",
    "os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through the files in the source directory\n",
    "for ff in os.listdir(source_dir):\n",
    "    # Check if the file name (without extension) ends with 't', case-insensitive\n",
    "    if ff.split(\".\")[0].lower().endswith(\"t\"):\n",
    "        # Construct the full path of the source and destination files\n",
    "        source_file = os.path.join(source_dir, ff)\n",
    "        dest_file = os.path.join(dest_dir, ff)\n",
    "        \n",
    "        # Check if the destination file already exists to avoid overwriting\n",
    "        if os.path.exists(dest_file):\n",
    "            print(f\"File {dest_file} already exists, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Copy the file from the source to destination directory\n",
    "            shutil.copy(source_file, dest_file)\n",
    "            print(f\"Successfully copied {source_file} to {dest_file}\")\n",
    "        except Exception as e:\n",
    "            # Handle any exceptions that occur during the copy\n",
    "            print(f\"Failed to copy {source_file} to {dest_file}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vg69osUfuGwv",
    "outputId": "6d27280c-b9df-4c4a-9f5f-af25d03d3e03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Leave-One-Out Cross Validation (LOOCV):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chunks(data, length=512, ovlp=51, num_chunks=34, start_point=-1): \n",
    "        '''2 seconds, 0.2 seconds overlap'''\n",
    "        all_chunks = []\n",
    "        total_len = data.shape[1]\n",
    "        actual_num_chunks = num_chunks\n",
    "        \n",
    "        if start_point == -1:\n",
    "            if num_chunks * length > total_len - 1:\n",
    "                start_point = 0\n",
    "                actual_num_chunks = total_len // length\n",
    "            else:\n",
    "                start_point = np.random.randint(0, total_len - num_chunks * length)\n",
    "        \n",
    "        for i in range(actual_num_chunks):\n",
    "            chunk = data[:, start_point: start_point + length]\n",
    "            all_chunks.append(np.array(chunk))\n",
    "            start_point = start_point + length - ovlp\n",
    "        return np.array(all_chunks), start_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(data_loader, model, criterion, optimizer, scheduler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        inputs, targets = batch  # Assuming batch returns inputs and targets\n",
    "       # inputs = split_chunks(inputs)\n",
    "       # inputs = torch.tensor(inputs, dtype=torch.float64)\n",
    "        print(inputs.shape)\n",
    "        print(inputs.unsqueeze(1).shape)\n",
    "        inputs = inputs[:, :, :-1]\n",
    "        # Prepare the batch in the required dictionary format\n",
    "        print(inputs.unsqueeze(1).shape)\n",
    "        model_batch = {'inputs': inputs.unsqueeze(1)}  # Unsqueezing along the third dimension\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(model_batch)  # Pass the dictionary to the model\n",
    "        logits = outputs['outputs']  # Adjust this if your model output structure is different\n",
    "\n",
    "        loss = criterion(logits, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(data_loader, model, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for batch in data_loader:\n",
    "            inputs, targets = batch  # Adjust according to your data format\n",
    "\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, targets)  # Compute the loss\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\encoder\\base.py:178: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from src/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\model.py:77: UserWarning: Warning: /!\\ Skipping unembedder.model.0.weight from src/pytorch_model.bin because it is not part of the current model\n",
      "  warnings.warn(\n",
      "c:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\model.py:77: UserWarning: Warning: /!\\ Skipping unembedder.model.0.bias from src/pytorch_model.bin because it is not part of the current model\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using A01T.gdf as test data, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> files remain for training.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using A01T.gdf as test data, \u001b[1;36m8\u001b[0m files remain for training.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Removed test\\A01T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Removed test\\A01T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Copied A01T.gdf to test/A01T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Copied A01T.gdf to test/A01T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">the file to be processed is:  train/A02T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "the file to be processed is:  train/A02T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">the file to be processed is:  train/A03T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "the file to be processed is:  train/A03T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">the file to be processed is:  train/A04T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "the file to be processed is:  train/A04T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">the file to be processed is:  train/A05T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "the file to be processed is:  train/A05T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">the file to be processed is:  train/A06T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "the file to be processed is:  train/A06T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">the file to be processed is:  train/A07T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "the file to be processed is:  train/A07T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">the file to be processed is:  train/A08T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "the file to be processed is:  train/A08T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">the file to be processed is:  train/A09T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "the file to be processed is:  train/A09T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">the file to be processed is:  test/A01T.gdf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "the file to be processed is:  test/A01T.gdf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m60\u001b[0m, \u001b[1;36m20\u001b[0m, \u001b[1;36m1537\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m60\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m20\u001b[0m, \u001b[1;36m1537\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1536</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m60\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m20\u001b[0m, \u001b[1;36m1536\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (30x7680 and 2240x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 191\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Training and validation loop\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;66;03m# Perform training and validation for the current epoch\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     trn_res \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     val_res \u001b[38;5;241m=\u001b[39m validation(test_loader, model, criterion) \n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# Update the best validation result if necessary\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[97], line 16\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(data_loader, model, criterion, optimizer, scheduler)\u001b[0m\n\u001b[0;32m     13\u001b[0m model_batch \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m: inputs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)}  \u001b[38;5;66;03m# Unsqueezing along the third dimension\u001b[39;00m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_batch\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass the dictionary to the model\u001b[39;00m\n\u001b[0;32m     17\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Adjust this if your model output structure is different\u001b[39;00m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, targets)\n",
      "File \u001b[1;32mc:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\shreyas\\Documents\\GitHub\\NeuroGPT\\src\\model.py:194\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, batch, prep_batch, return_batch)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03mForward pass of model.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    if prep_batch is True)\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m#before prep_batch masking and things, we need to first let the splitted chunks of raw input through the encoder\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m#attempt for trying fine-tune only the encoder, but the encoder cannot combine information across chunks.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoding_mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mft_only_encoder:\n",
      "File \u001b[1;32mc:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\NeuroGPT\\src\\encoder\\conformer_braindecode.py:169\u001b[0m, in \u001b[0;36mEEGConformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    165\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(x)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoding_mode:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# pdb.set_trace()\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer(x)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\NeuroGPT\\src\\encoder\\conformer_braindecode.py:397\u001b[0m, in \u001b[0;36m_FullyConnected.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    396\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 397\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (30x7680 and 2240x256)"
     ]
    }
   ],
   "source": [
    "# Define the source and destination directory for the data\n",
    "from decoder.make_decoder import make_decoder\n",
    "from embedder.make import make_embedder\n",
    "from encoder.conformer_braindecode import EEGConformer\n",
    "\n",
    "\n",
    "source_dir = \"train\"\n",
    "test_dir = \"test\"\n",
    "# Example default configuration\n",
    "model_config = {\n",
    "  \"train_data_path\": \"C:\\\\Users\\\\shreyas\\\\Documents\\\\GitHub\\\\NeuroGPT\\\\tuh_tensors\\\\\",\n",
    "  \"parcellation_dim\": 1120,\n",
    "  \"pretrained_model\": None,\n",
    "  \"embedding_dim\": 1024,\n",
    "  \"num_hidden_layers_embedding_model\": 1,\n",
    "  \"freeze_embedder\": False,\n",
    "  \"num_hidden_layers_unembedding_model\": 1,\n",
    "  \"freeze_unembedder\": False,\n",
    "  \"architecture\": \"GPT\",\n",
    "  \"num_hidden_layers\": 6,\n",
    "  \"num_attention_heads\": 16,\n",
    "  \"intermediate_dim_factor\": 4,\n",
    "  \"hidden_activation\": \"gelu_new\",\n",
    "  \"freeze_decoder\": False,\n",
    "  \"freeze_decoder_without_pooler_heads\": None,\n",
    "  \"resume_from\": None,\n",
    "  \"training_style\": \"CSM\",\n",
    "  \"decoding_target\": None,\n",
    "  \"num_decoding_classes\": 4,\n",
    "  \"training_steps\": 5,\n",
    "  \"validation_steps\": 1000,\n",
    "  \"test_steps\": 1000,\n",
    "  \"per_device_training_batch_size\": 1,\n",
    "  \"per_device_validation_batch_size\": 1,\n",
    "  \"optim\": \"adamw_hf\",\n",
    "  \"learning_rate\": 0.0001,\n",
    "  \"warmup_ratio\": 0.01,\n",
    "  \"weight_decay\": 0.1,\n",
    "  \"adam_beta_1\": 0.9,\n",
    "  \"adam_beta_2\": 0.999,\n",
    "  \"adam_epsilon\": 1e-08,\n",
    "  \"max_grad_norm\": 1.0,\n",
    "  \"lr_scheduler\": \"linear\",\n",
    "  \"dropout\": 0.1,\n",
    "  \"log_dir\": \"results/models/upstream\\\\32clen2_embed1024\",\n",
    "  \"log_every_n_steps\": 4,\n",
    "  \"run_name\": \"32clen2_embed1024\",\n",
    "  \"wandb_mode\": \"disabled\",\n",
    "  \"wandb_project_name\": \"learning-from-brains\",\n",
    "  \"seed\": 1234,\n",
    "  \"set_seed\": True,\n",
    "  \"fp16\": True,\n",
    "  \"deepspeed\": None,\n",
    "  \"local_rank\": -1,\n",
    "  \"num_workers\": 1,\n",
    "  \"plot_model_graph\": False,\n",
    "  \"smoke_test\": False,\n",
    "  \"bold_dummy_mode\": False,\n",
    "  \"do_train\": True,\n",
    "  \"n_positions\": 512,\n",
    "  \"chunk_len\": 512,\n",
    "  \"num_chunks\": 34,\n",
    "  \"chunk_ovlp\": 51,\n",
    "  \"sampling_rate\": 250,\n",
    "  \"fold_i\": 0,\n",
    "  \"use_encoder\": True,\n",
    "  \"do_normalization\": True,\n",
    "  \"filter_time_length\": 25,\n",
    "  \"pool_time_length\": 75,\n",
    "  \"stride_avg_pool\": 15,\n",
    "  \"n_filters_time\": 40,\n",
    "  \"num_encoder_layers\": 6,\n",
    "  \"eval_every_n_steps\": 4,\n",
    "  \"freeze_encoder\": False,\n",
    "  \"ft_only_encoder\": 'True'\n",
    "}\n",
    "\n",
    "\n",
    "# Ensure the destination directory exists, if not create it\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "encoder = EEGConformer(n_outputs=model_config[\"num_decoding_classes\"], n_chans=20, n_times=model_config['chunk_len'], ch_pos=None, is_decoding_mode=model_config[\"ft_only_encoder\"])\n",
    "embedder = make_embedder(\n",
    "        training_style=model_config[\"training_style\"],\n",
    "        architecture=model_config[\"architecture\"],\n",
    "        in_dim=model_config[\"parcellation_dim\"], # flattened, channel x chunk length\n",
    "        embed_dim=model_config[\"embedding_dim\"],\n",
    "        num_hidden_layers=model_config[\"num_hidden_layers_embedding_model\"],\n",
    "        dropout=model_config[\"dropout\"],\n",
    "        n_positions=model_config[\"n_positions\"]\n",
    "    )\n",
    "decoder = make_decoder(\n",
    "        architecture=model_config[\"architecture\"],\n",
    "        num_hidden_layers=model_config[\"num_hidden_layers\"],\n",
    "        embed_dim=model_config[\"embedding_dim\"],\n",
    "        num_attention_heads=model_config[\"num_attention_heads\"],\n",
    "        n_positions=model_config[\"n_positions\"],\n",
    "        intermediate_dim_factor=model_config[\"intermediate_dim_factor\"],\n",
    "        hidden_activation=model_config[\"hidden_activation\"],\n",
    "        dropout=model_config[\"dropout\"]\n",
    "    )\n",
    "model = Model(encoder,embedder,decoder)\n",
    "model.from_pretrained(\"src/pytorch_model.bin\")\n",
    "\n",
    "# Configure the model for encoder-only fine-tuning\n",
    "model.switch_ft_mode(ft_encoder_only=True)\n",
    "\n",
    "\n",
    "# List and sort all files in the source directory\n",
    "all_data = os.listdir(source_dir)\n",
    "all_data.sort()\n",
    "\n",
    "# Initialize lists to store validation and training results\n",
    "val_results = []\n",
    "trn_results = []\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "  # Fraction of the cycle (total training steps) spent increasing the learning rate\n",
    "\n",
    "\n",
    "# Loop through all files, treating each file as the test data in turn\n",
    "for i in range(len(all_data)):\n",
    "    # Pop the test data file from the list\n",
    "    test_data = all_data.pop(i)\n",
    "    print(f\"Using {test_data} as test data, {len(all_data)} files remain for training.\")\n",
    "    \n",
    "    # Empty the test directory if it contains any files\n",
    "    for file in os.listdir(test_dir):\n",
    "        file_path = os.path.join(test_dir, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "            print(f\"Removed {file_path}\")\n",
    "    \n",
    "    # Copy the test data file to the test directory\n",
    "    shutil.copy(f\"{source_dir}/{test_data}\", f\"{test_dir}/{test_data}\")\n",
    "    print(f\"Copied {test_data} to {test_dir}/{test_data}\")\n",
    "    \n",
    "    # Initialize empty lists to store DataFrames and indices\n",
    "    dfs = []\n",
    "    idxs = []\n",
    "    # Process each training file and accumulate the data and indices\n",
    "    for trn_file in all_data:\n",
    "        dd, idd = process_gdf_file(f\"{source_dir}/{trn_file}\")\n",
    "        dfs.append(dd)\n",
    "        idxs += idd\n",
    "    \n",
    "    # Concatenate all training data into a single DataFrame\n",
    "    train_df = pd.concat(dfs, axis=0)\n",
    "    # Set multi-index for the training DataFrame\n",
    "    train_df.set_index([\"person\", \"epoch\"], inplace=True)\n",
    "    # Drop the 'time' column as it's not needed\n",
    "    train_df.drop(\"time\", inplace=True, axis=1)\n",
    "    \n",
    "    # Process the test data file\n",
    "    test_df, test_idxs = process_gdf_file(f\"{test_dir}/{test_data}\")\n",
    "    # Drop the 'time' column from the test DataFrame as well\n",
    "    test_df.drop(\"time\", axis=1, inplace=True)\n",
    "    # Set multi-index for the test DataFrame\n",
    "    test_df.set_index([\"person\", \"epoch\"], inplace=True)\n",
    "    \n",
    "    # Initialize the pre-trained model and the linear classifier\n",
    "    # Code needs to be added\n",
    "    \n",
    "    # Set up the optimizer for training\n",
    "    # Code needs to be added\n",
    "    \n",
    "    # Create DataLoader instances for training and testing data\n",
    "    trn_dataset = EEGDatasetCls(train_df, idxs)\n",
    "    train_loader = DataLoader(trn_dataset, 60, pin_memory=True)\n",
    "    test_dataset = EEGDatasetCls(test_df, test_idxs)\n",
    "    test_loader = DataLoader(test_dataset, 60, pin_memory=True)\n",
    "    \n",
    "    # Define the number of epochs and set up the learning rate scheduler\n",
    "    epochs = 15\n",
    "    pct_start = 0.3\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=5e-5,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        epochs=epochs,\n",
    "        pct_start= pct_start,\n",
    "    )\n",
    "    # Define the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Initialize the best validation accuracy to zero\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    # Training and validation loop\n",
    "    for e in tqdm(range(epochs)):\n",
    "        # Perform training and validation for the current epoch\n",
    "        trn_res = training(train_loader, model, criterion, optimizer, scheduler)\n",
    "        val_res = validation(test_loader, model, criterion) \n",
    "        \n",
    "        # Update the best validation result if necessary\n",
    "        if val_res[\"acc\"] >= best_val_acc:\n",
    "            best_val = val_res\n",
    "            best_val_acc = val_res[\"acc\"]\n",
    "        \n",
    "        # Print the training and validation results for the current epoch\n",
    "        print(\n",
    "            \"Epoch %d: trn_loss %.4f val_loss %.4f val_acc %.4f trn_acc %.4f\"\n",
    "            % (e, trn_res[\"loss\"], val_res[\"loss\"], val_res[\"acc\"], trn_res[\"acc\"])\n",
    "        )\n",
    "    \n",
    "    # Append the training and validation results to the results lists\n",
    "    trn_results.append(trn_res)\n",
    "    val_results.append(best_val)\n",
    "    \n",
    "    # Delete the linear classifier to free up GPU memory\n",
    "    \n",
    "    \n",
    "    # Reinsert the test_data back into all_data for the next iteration\n",
    "    all_data.insert(i, test_data)\n",
    "    print(f\"Reinserted {test_data} back into all_data for the next iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m20\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1383</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1383\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Input tensor:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Input tensor:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(v[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput tensor:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shreyas\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\NeuroGPT\\src\\encoder\\conformer_braindecode.py:159\u001b[0m, in \u001b[0;36mEEGConformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 159\u001b[0m     batch, chunks, chann, time \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(batch\u001b[38;5;241m*\u001b[39mchunks, chann, time)\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# x = x.permute(0, 2, 1, 3).contiguous().view(batch, chann, -1)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "k = torch.rand([20,1537])\n",
    "v = split_chunks(k)\n",
    "n = torch.tensor(v[0], dtype=torch.float64)\n",
    "print(v[1])\n",
    "print(\"Input tensor:\")\n",
    "encoder(v[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rTlOVEvNhBfZ",
    "outputId": "87c66a27-b25b-495f-eb75-9623e1a2d634"
   },
   "outputs": [],
   "source": [
    "# Leave-One-Out Cross Validation (LOOCV):\n",
    "val_results = []\n",
    "trn_results = []\n",
    "for i in range(len(os.listdir(\"train\"))):\n",
    "    all_data = os.listdir(\"train\")\n",
    "    all_data.sort()\n",
    "\n",
    "    test_data = all_data.pop(i)\n",
    "    print(test_data, len(all_data))\n",
    "    shutil.rmtree(\"test\")\n",
    "    os.mkdir(\"test\")\n",
    "    shutil.copy(f\"train/{test_data}\", f\"test/{test_data}\")\n",
    "\n",
    "    dfs = []\n",
    "    idxs = []\n",
    "\n",
    "    for trn_file in all_data:\n",
    "        dd, idd = process_gdf_file(f\"train/{trn_file}\")\n",
    "        dfs.append(dd)\n",
    "        idxs += idd\n",
    "\n",
    "    train_df = pd.concat(dfs, axis=0)\n",
    "    train_df.set_index([\"person\", \"epoch\"], inplace=True)\n",
    "    train_df.drop(\"time\", inplace=True, axis=1)\n",
    "\n",
    "    test_df, test_idxs = process_gdf_file(f\"test/{test_data}\")\n",
    "    test_df.drop(\"time\", axis=1, inplace=True)\n",
    "    test_df.set_index([\"person\", \"epoch\"], inplace=True)\n",
    "\n",
    "\n",
    "    trn_dataset = EEGDatasetCls(train_df, idxs)\n",
    "    train_loader = DataLoader(trn_dataset, 60, pin_memory=True)\n",
    "\n",
    "    test_dataset = EEGDatasetCls(test_df, test_idxs)\n",
    "    test_loader = DataLoader(test_dataset, 60, pin_memory=True)\n",
    "\n",
    "    epochs = 15\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=5e-5,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        epochs=epochs,\n",
    "        pct_start= pct_start,\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    for e in tqdm(range(epochs)):\n",
    "        trn_res = training(\n",
    "            train_loader, linear_classifier, criterion, optimizer, scheduler\n",
    "        )\n",
    "        val_res = validation(test_loader, linear_classifier, criterion)\n",
    "\n",
    "        if val_res[\"acc\"] >= best_val_acc:\n",
    "            best_val = val_res\n",
    "            best_val_acc = val_res[\"acc\"]\n",
    "        print(\n",
    "            \"trn_loss %.4f val_loss %.4f val_acc %.4f trn_acc %.4f\"\n",
    "            % (trn_res[\"loss\"], val_res[\"loss\"], val_res[\"acc\"], trn_res[\"acc\"])\n",
    "        )\n",
    "\n",
    "    trn_results.append(trn_res)\n",
    "    val_results.append(best_val)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
